[tool:pytest-benchmark]
# Benchmark configuration for pytest-benchmark

# Minimum number of rounds to run each benchmark
min_rounds = 5

# Maximum time to spend on each benchmark (in seconds)
max_time = 10.0

# Minimum time to spend on each benchmark (in seconds)
min_time = 0.1

# Timer to use for benchmarking
timer = time.perf_counter

# Disable garbage collection during benchmarking for more consistent results
disable_gc = true

# Warmup rounds before actual benchmarking
warmup = true
warmup_iterations = 2

# Output format
output_format = table

# Sort results by
sort = mean

# Columns to display
columns = min,max,mean,stddev,median,iqr,outliers,ops,rounds

# Save benchmark results
save = .benchmarks
save_data = true

# Compare with previous results
compare = 0001
compare_fail = mean:5%

# Calibration
calibration_precision = 10
calibration_bias = 1e-6

# Skip benchmarks that are too slow
skip_slow = false

# Group benchmarks
group_by = group
